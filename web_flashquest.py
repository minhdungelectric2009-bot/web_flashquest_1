import streamlit as st
import os
import docx
import PyPDF2
# import pytesseract  <-- ÄÃƒ XÃ“A (KhÃ´ng cáº§n ná»¯a)
import base64  # <-- Má»šI: DÃ¹ng Ä‘á»ƒ mÃ£ hÃ³a áº£nh gá»­i cho AI
from PIL import Image
import json
from groq import Groq, RateLimitError, APIError

# ==========================================
# PHáº¦N 1: LOGIC Xá»¬ LÃ (BACKEND)
# ==========================================
class StudyMaterialProcessor:
    def __init__(self, selected_model_id):
        # Láº¥y API Key
        try:
            api_key = st.secrets["GROQ_API_KEY"]
        except Exception:
            st.error("âš ï¸ ChÆ°a cáº¥u hÃ¬nh GROQ_API_KEY trong Streamlit Secrets!")
            api_key = None
        
        self.model_id = selected_model_id

        if api_key:
            try:
                self.client = Groq(api_key=api_key)
            except Exception as e:
                st.error(f"Lá»—i káº¿t ná»‘i Groq: {e}")
                self.client = None
        else:
            self.client = None

    def extract_text_from_docx(self, file_path):
        try:
            doc = docx.Document(file_path)
            return '\n'.join([para.text for para in doc.paragraphs])
        except: return ""

    def extract_text_from_pdf(self, file_path):
        try:
            text = ""
            with open(file_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                for page in reader.pages:
                    text += page.extract_text() + "\n"
            return text
        except: return ""

    # ðŸ‘‡ CODE Má»šI: DÃ¹ng AI Vision thay cho Tesseract ðŸ‘‡
    def extract_text_from_image(self, file_path):
        if not self.client: return ""
        try:
            # 1. MÃ£ hÃ³a áº£nh thÃ nh Base64 Ä‘á»ƒ gá»­i qua máº¡ng
            with open(file_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')

            # 2. Gá»i model Llama Vision (chuyÃªn Ä‘á»c áº£nh)
            # LÆ°u Ã½: LuÃ´n dÃ¹ng model Vision cho bÆ°á»›c nÃ y, báº¥t ká»ƒ ngÆ°á»i dÃ¹ng chá»n model nÃ o á»Ÿ ngoÃ i
            vision_model = "llama-3.2-11b-vision-preview" 

            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "HÃ£y trÃ­ch xuáº¥t toÃ n bá»™ vÄƒn báº£n cÃ³ trong hÃ¬nh áº£nh nÃ y. Chá»‰ tráº£ vá» ná»™i dung vÄƒn báº£n, khÃ´ng thÃªm lá»i bÃ¬nh luáº­n hay mÃ´ táº£."},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                },
                            },
                        ],
                    }
                ],
                model=vision_model,
            )
            return chat_completion.choices[0].message.content
        except Exception as e:
            return f"Lá»—i Ä‘á»c áº£nh báº±ng AI: {str(e)}"

    def process_file(self, file_path):
        _, ext = os.path.splitext(file_path)
        ext = ext.lower()
        
        raw_text = ""
        if ext == '.docx': raw_text = self.extract_text_from_docx(file_path)
        elif ext == '.pdf': raw_text = self.extract_text_from_pdf(file_path)
        elif ext in ['.jpg', '.jpeg', '.png']: raw_text = self.extract_text_from_image(file_path)
        
        if not raw_text or not raw_text.strip():
            return {"error_type": "DATA", "message": "KhÃ´ng Ä‘á»c Ä‘Æ°á»£c ná»™i dung text tá»« file nÃ y."}

        # Sau khi cÃ³ text, má»›i dÃ¹ng model ngÆ°á»i dÃ¹ng chá»n Ä‘á»ƒ phÃ¢n tÃ­ch
        return self.analyze_with_ai(raw_text)

    def analyze_with_ai(self, text):
        if not self.client: return {"error_type": "CONFIG", "message": "Lá»—i: ChÆ°a cáº¥u hÃ¬nh API Key."}
        
        try:
            prompt = f"""
            Báº¡n lÃ  chuyÃªn gia giÃ¡o dá»¥c. Nhiá»‡m vá»¥: Táº¡o bá»™ cÃ¢u há»i tráº¯c nghiá»‡m phá»§ kÃ­n 100% ná»™i dung tÃ i liá»‡u.
            Ná»™i dung: "{text[:20000]}" 
            
            YÃªu cáº§u JSON Ä‘áº§u ra:
            1. "tom_tat": TÃ³m táº¯t 3 pháº§n (Má»Ÿ, ThÃ¢n, Káº¿t).
            2. "goi_y_hoc": 5 phÆ°Æ¡ng phÃ¡p há»c táº­p.
            3. "tu_khoa": 10-15 tá»« khÃ³a.
            4. "cau_hoi_quiz": Táº¡o bá»™ cÃ¢u há»i (KhÃ´ng giá»›i háº¡n, cÃ ng nhiá»u cÃ ng tá»‘t).
            
            Tráº£ vá» JSON Ä‘Ãºng máº«u:
            {{
                "tom_tat": "...",
                "goi_y_hoc": ["..."],
                "tu_khoa": ["..."],
                "cau_hoi_quiz": [{{"cau_hoi": "...", "dap_an": "..."}}]
            }}
            """

            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½ JSON. Chá»‰ tráº£ vá» JSON há»£p lá»‡."},
                    {"role": "user", "content": prompt}
                ],
                model=self.model_id, 
                temperature=0.5,
                max_tokens=7500,
                response_format={"type": "json_object"} 
            )
            
            return json.loads(chat_completion.choices[0].message.content)

        except RateLimitError:
            return {"error_type": "RATE_LIMIT", "message": f"â›” Model {self.model_id} háº¿t lÆ°á»£t."}
        except APIError as e:
            return {"error_type": "API", "message": f"Lá»—i API: {str(e)}"}
        except Exception as e:
            return {"error_type": "UNKNOWN", "message": f"Lá»—i: {str(e)}"}

# ==========================================
# PHáº¦N 2: GIAO DIá»†N WEB
# ==========================================
def main():
    st.set_page_config(page_title="FlashQuest - Smart Select", page_icon="âš¡", layout="wide")
    st.title("âš¡ FlashQuest - Há»c táº­p thÃ´ng minh")

    with st.sidebar:
        st.header("ðŸ§  Chá»n Bá»™ NÃ£o AI")
        model_options = {
            "ðŸ† Llama 3.3 (ThÃ´ng minh nháº¥t - 70B)": "llama-3.3-70b-versatile",
            "ðŸš€ Llama 3.1 (SiÃªu tá»‘c - 8B)": "llama-3.1-8b-instant"
        }
        selected_name = st.selectbox("MÃ´ hÃ¬nh xá»­ lÃ½:", options=list(model_options.keys()), index=0)
        selected_model_id = model_options[selected_name]
        
        st.info("ðŸ“· **TÃ­nh nÄƒng áº£nh:** Tá»± Ä‘á»™ng dÃ¹ng Llama 3.2 Vision Ä‘á»ƒ Ä‘á»c áº£nh (KhÃ´ng cáº§n cÃ i pháº§n má»m).")

    uploaded_file = st.file_uploader("Táº£i lÃªn tÃ i liá»‡u", type=['docx', 'pdf', 'jpg', 'png', 'jpeg'])

    if uploaded_file is not None:
        file_path = uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"ÄÃ£ nháº­n file: {uploaded_file.name}")

        if st.button("âœ¨ PhÃ¢n tÃ­ch ngay"):
            processor = StudyMaterialProcessor(selected_model_id)
            
            with st.spinner(f"AI Ä‘ang Ä‘á»c tÃ i liá»‡u vÃ  phÃ¢n tÃ­ch..."):
                result = processor.process_file(file_path)
            
            if os.path.exists(file_path): os.remove(file_path)

            if "error_type" in result:
                st.error(result["message"])
            else:
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.subheader("ðŸ“ TÃ³m táº¯t")
                    st.info(result.get("tom_tat", ""))
                    st.subheader("ðŸ’¡ Gá»£i Ã½ há»c")
                    for gy in result.get("goi_y_hoc", []): st.markdown(f"- {gy}")
                with col2:
                    st.subheader("ðŸ”‘ Tá»« khÃ³a")
                    for kw in result.get("tu_khoa", []): st.button(f"ðŸ·ï¸ {kw}", use_container_width=True)
                
                st.divider()
                st.subheader("â“ CÃ¢u há»i tráº¯c nghiá»‡m")
                for idx, q in enumerate(result.get("cau_hoi_quiz", []), 1):
                    with st.expander(f"CÃ¢u {idx}: {q.get('cau_hoi')}"):
                        st.markdown(f"**ÄÃ¡p Ã¡n:** {q.get('dap_an')}")

if __name__ == "__main__":
    main()
