import streamlit as st
import os
import docx
import PyPDF2
import pytesseract
from PIL import Image
import json
from groq import Groq, RateLimitError, APIError

# --- C·∫§U H√åNH ---
if os.name == 'nt':
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ==========================================
# PH·∫¶N 1: LOGIC X·ª¨ L√ù (BACKEND)
# ==========================================
class StudyMaterialProcessor:
    def __init__(self, selected_model_id):
        # --- API KEY ---
        api_key = "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" 
        
        # L∆∞u model ID ƒë∆∞·ª£c ch·ªçn t·ª´ giao di·ªán
        self.model_id = selected_model_id

        try:
            self.client = Groq(api_key=api_key)
        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi Groq: {e}")
            self.client = None

    def extract_text_from_docx(self, file_path):
        try:
            doc = docx.Document(file_path)
            return '\n'.join([para.text for para in doc.paragraphs])
        except: return ""

    def extract_text_from_pdf(self, file_path):
        try:
            text = ""
            with open(file_path, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                for page in reader.pages:
                    text += page.extract_text() + "\n"
            return text
        except: return ""

    def extract_text_from_image(self, file_path):
        try:
            img = Image.open(file_path)
            return pytesseract.image_to_string(img, lang='vie+eng')
        except: return ""

    def process_file(self, file_path):
        _, ext = os.path.splitext(file_path)
        ext = ext.lower()
        
        raw_text = ""
        if ext == '.docx': raw_text = self.extract_text_from_docx(file_path)
        elif ext == '.pdf': raw_text = self.extract_text_from_pdf(file_path)
        elif ext in ['.jpg', '.jpeg', '.png']: raw_text = self.extract_text_from_image(file_path)
        
        if not raw_text.strip():
            return {"error_type": "DATA", "message": "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung text t·ª´ file n√†y."}

        return self.analyze_with_ai(raw_text)

    def analyze_with_ai(self, text):
        if not self.client: return {"error_type": "CONFIG", "message": "L·ªói: Ch∆∞a c√≥ API Key"}
        
        try:
            # Prompt "Ph·ªß k√≠n n·ªôi dung"
            prompt = f"""
            B·∫°n l√† chuy√™n gia gi√°o d·ª•c. Nhi·ªám v·ª•: T·∫°o b·ªô c√¢u h·ªèi tr·∫Øc nghi·ªám ph·ªß k√≠n 100% n·ªôi dung t√†i li·ªáu.
            N·ªôi dung: "{text[:18000]}" 
            
            Y√™u c·∫ßu JSON ƒë·∫ßu ra:
            1. "tom_tat": T√≥m t·∫Øt 3 ph·∫ßn (M·ªü, Th√¢n, K·∫øt) th·∫≠t chi ti·∫øt.
            2. "goi_y_hoc": 5 ph∆∞∆°ng ph√°p h·ªçc.
            3. "tu_khoa": 10-15 t·ª´ kh√≥a.
            4. "cau_hoi_quiz": T·∫°o s·ªë l∆∞·ª£ng c√¢u h·ªèi KH√îNG GI·ªöI H·∫†N, t√πy thu·ªôc v√†o ƒë·ªô d√†i t√†i li·ªáu.
               - T√†i li·ªáu d√†i ph·∫£i c√≥ nhi·ªÅu c√¢u h·ªèi (20-50 c√¢u) ƒë·ªÉ r·∫£i ƒë·ªÅu ki·∫øn th·ª©c.
               - ƒê·∫£m b·∫£o h·ªçc xong quiz l√† thu·ªôc h·∫øt b√†i.
            
            Tr·∫£ v·ªÅ JSON ƒë√∫ng m·∫´u:
            {{
                "tom_tat": "...",
                "goi_y_hoc": ["..."],
                "tu_khoa": ["..."],
                "cau_hoi_quiz": [{{"cau_hoi": "...", "dap_an": "..."}}]
            }}
            """

            # G·ªçi Groq API v·ªõi Model ƒë∆∞·ª£c ch·ªçn
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω JSON. Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá."},
                    {"role": "user", "content": prompt}
                ],
                model=self.model_id, # <-- D√πng model ng∆∞·ªùi d√πng ch·ªçn
                temperature=0.5,
                max_tokens=7000, 
                response_format={"type": "json_object"} 
            )
            
            return json.loads(chat_completion.choices[0].message.content)

        # --- B·∫ÆT L·ªñI RATE LIMIT & QUOTA ---
        except RateLimitError:
            return {
                "error_type": "RATE_LIMIT", 
                "message": f"üö® Model {self.model_id} ƒë√£ H·∫æT L∆Ø·ª¢T ho·∫∑c QU√Å T·∫¢I!\nüëâ Vui l√≤ng ch·ªçn Model kh√°c ·ªü thanh b√™n tr√°i."
            }
        except APIError as e:
            if "429" in str(e) or "rate limit" in str(e).lower():
                return {
                    "error_type": "RATE_LIMIT", 
                    "message": f"üö® Model {self.model_id} ƒëang b·∫≠n ho·∫∑c h·∫øt l∆∞·ª£t!\nüëâ H√£y ƒë·ªïi sang Model kh√°c (v√≠ d·ª• Llama 3.1)."
                }
            return {"error_type": "API", "message": f"L·ªói API: {str(e)}"}
        except Exception as e:
            return {"error_type": "UNKNOWN", "message": f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"}

# ==========================================
# PH·∫¶N 2: GIAO DI·ªÜN WEB
# ==========================================
def main():
    st.set_page_config(page_title="FlashQuest - AI Selector", page_icon="‚ö°", layout="wide")

    st.title("‚ö° FlashQuest - H·ªçc t·∫≠p si√™u t·ªëc")

    # --- THANH B√äN: CH·ªåN MODEL ---
    with st.sidebar:
        st.header("üß† C·∫•u h√¨nh b·ªô n√£o AI")
        
        # Danh s√°ch Model t·ªëi ∆∞u nh·∫•t t·ª´ ·∫£nh b·∫°n g·ª≠i
        model_options = {
            "üèÜ Llama 3.3 (Th√¥ng minh nh·∫•t - 70B)": "llama-3.3-70b-versatile",
            "üöÄ Llama 3.1 (Si√™u t·ªëc/Nhi·ªÅu l∆∞·ª£t - 8B)": "llama-3.1-8b-instant",
            "ü§ñ Qwen 2.5/3 (Logic t·ªët - 32B)": "qwen-2.5-32b", # Ho·∫∑c qwen/qwen3-32b n·∫øu c√≥
        }
        
        selected_name = st.selectbox(
            "Ch·ªçn m√¥ h√¨nh ph√¢n t√≠ch:",
            options=list(model_options.keys()),
            index=0 # M·∫∑c ƒë·ªãnh ch·ªçn c√°i x·ªãn nh·∫•t
        )
        
        # L·∫•y ID th·ª±c t·∫ø ƒë·ªÉ g·ª≠i cho API
        selected_model_id = model_options[selected_name]
        
        st.info(f"ƒêang d√πng: **{selected_model_id}**")
        st.caption("M·∫πo: N·∫øu g·∫∑p l·ªói h·∫øt l∆∞·ª£t, h√£y ƒë·ªïi sang d√≤ng 'Si√™u t·ªëc' (Llama 3.1).")
        st.divider()
        st.write("H∆∞·ªõng d·∫´n:\n1. T·∫£i t√†i li·ªáu.\n2. B·∫•m Ph√¢n t√≠ch.\n3. ƒê·ªïi model n·∫øu c·∫ßn.")

    # --- PH·∫¶N CH√çNH ---
    uploaded_file = st.file_uploader("T·∫£i l√™n t√†i li·ªáu (Word, PDF, ·∫¢nh)", type=['docx', 'pdf', 'jpg', 'png', 'jpeg'])

    if uploaded_file is not None:
        file_path = uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"ƒê√£ nh·∫≠n file: {uploaded_file.name}")

        if st.button("‚ú® Ph√¢n t√≠ch ngay"):
            # Truy·ªÅn model ID v√†o b·ªô x·ª≠ l√Ω
            processor = StudyMaterialProcessor(selected_model_id)
            
            with st.spinner(f"AI ({selected_model_id}) ƒëang ƒë·ªçc v√† so·∫°n c√¢u h·ªèi..."):
                result = processor.process_file(file_path)
            
            if os.path.exists(file_path): os.remove(file_path)

            # --- X·ª¨ L√ù L·ªñI ---
            if "error_type" in result:
                err_type = result["error_type"]
                msg = result["message"]
                
                if err_type == "RATE_LIMIT":
                    st.error(msg, icon="üö´") # Hi·ªán l·ªói ƒë·ªè th·∫≠t to
                    st.toast("H√£y ƒë·ªïi Model b√™n thanh tr√°i!", icon="üëà")
                else:
                    st.error(msg)
            
            # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
            else:
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.subheader("üìù T√≥m t·∫Øt chuy√™n s√¢u")
                    st.info(result.get("tom_tat", ""))
                    
                    st.subheader("üí° Chi·∫øn l∆∞·ª£c h·ªçc")
                    for gy in result.get("goi_y_hoc", []):
                        st.markdown(f"- {gy}")

                with col2:
                    st.subheader("üîë T·ª´ kh√≥a")
                    for kw in result.get("tu_khoa", []):
                        st.button(f"üè∑Ô∏è {kw}", use_container_width=True)

                st.divider()
                quiz_list = result.get("cau_hoi_quiz", [])
                st.subheader(f"‚ùì Ng√¢n h√†ng c√¢u h·ªèi ({len(quiz_list)} c√¢u)")
                
                if not quiz_list:
                    st.warning("Kh√¥ng t·∫°o ƒë∆∞·ª£c c√¢u h·ªèi n√†o.")
                else:
                    for idx, q in enumerate(quiz_list, 1):
                        with st.expander(f"C√¢u {idx}: {q.get('cau_hoi')}"):
                            st.markdown(f"**ƒê√°p √°n:** {q.get('dap_an')}")

if __name__ == "__main__":
    main()
